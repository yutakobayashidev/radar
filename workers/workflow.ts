import { WorkflowEntrypoint, type WorkflowStep, type WorkflowEvent } from 'cloudflare:workers';
import { drizzle } from "drizzle-orm/d1";
import { parseFeed } from "htmlparser2";
import { eq } from "drizzle-orm";
import * as schema from "../db/schema";

type FeedData = NonNullable<ReturnType<typeof parseFeed>>;

export class MyWorkflow extends WorkflowEntrypoint<Env> {
  override async run(_event: WorkflowEvent<Params>, step: WorkflowStep) {
    const db = drizzle(this.env.DB, { schema });
    console.log("ğŸš€ Workflow started");

    // Step 1: RSS fetch + æ–°ç€åˆ¤å®š (çµ±åˆã—ã¦çŠ¶æ…‹ã‚µã‚¤ã‚ºã‚’å‰Šæ¸›)
    const newItems = await step.do("Fetch RSS feeds and filter new items", {
      retries: {
        limit: 1,
        delay: "10 seconds",
      }
    }, async () => {
      console.log("ğŸ“¡ Step 1: Fetching RSS feeds from all sources...");
      const sources = await db.query.sources.findMany();
      console.log(`ğŸ“‹ Found ${sources.length} sources to fetch`);

      // 1ã‹æœˆå‰ã®æ—¥ä»˜ã‚’è¨ˆç®—
      const oneMonthAgo = new Date();
      oneMonthAgo.setMonth(oneMonthAgo.getMonth() - 1);

      const filtered: Array<{
        sourceId: string;
        sourceName: string;
        title: string;
        url: string;
        description: string;
        pubDate: string | null;
      }> = [];
      let totalItems = 0;
      let skippedOldItems = 0;

      for (const source of sources) {
        try {
          console.log(`ğŸ“¥ Fetching: ${source.name} (${source.url})`);
          const response = await fetch(source.url);
          if (!response.ok) {
            console.error(`âŒ Failed to fetch ${source.url}: ${response.status}`);
            continue;
          }

          const htmlString = await response.text();
          const feed = parseFeed(htmlString);

          if (!feed || !feed.items) {
            console.error(`âš ï¸  No feed items found for ${source.url}`);
            continue;
          }

          console.log(`âœ… ${source.name}: ${feed.items.length} items`);
          let newCount = 0;

          for (const item of feed.items) {
            totalItems++;
            const url = item.link || "";

            // æ—¥ä»˜ãƒã‚§ãƒƒã‚¯: 1ã‹æœˆä»¥å†…ã®ã‚¢ã‚¤ãƒ†ãƒ ã®ã¿
            if (item.pubDate) {
              const itemDate = new Date(item.pubDate);
              if (itemDate < oneMonthAgo) {
                skippedOldItems++;
                continue;
              }
            }

            // URLã§æ—¢å­˜ãƒã‚§ãƒƒã‚¯
            const existing = await db.query.radarItems.findFirst({
              where: eq(schema.radarItems.url, url),
            });

            if (!existing && url) {
              // å¿…è¦æœ€å°é™ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ä¿å­˜ï¼ˆdescriptionã¯çŸ­ç¸®ï¼‰
              filtered.push({
                sourceId: source.id,
                sourceName: source.name,
                title: item.title || "Untitled",
                url,
                description: (item.description || "").substring(0, 300), // 300æ–‡å­—ã«åˆ¶é™
                pubDate: item.pubDate ? String(item.pubDate) : null,
              });
              newCount++;
            }
          }

          if (newCount > 0) {
            console.log(`ğŸ“Œ ${source.name}: ${newCount} new items`);
          }
        } catch (error) {
          console.error(`âŒ Error fetching ${source.url}:`, error);
        }
      }

      console.log(`âœ… Step 1 complete: ${filtered.length} new items out of ${totalItems} total (skipped ${skippedOldItems} old items)`);
      return filtered;
    });

    // Step 2: OGPå–å¾— (å¤±æ•—æ™‚ã¯RSS descriptionã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)
    const itemsWithOGP = await step.do("Fetch OGP data", async () => {
      console.log(`ğŸ–¼ï¸  Step 2: Fetching OGP data for ${newItems.length} items...`);
      const results = [];
      let ogpSuccessCount = 0;

      for (const item of newItems) {
        let image = "";
        let summary = item.description;

        try {
          const response = await fetch(item.url);
          if (response.ok) {
            const html = await response.text();
            const ogImageMatch = html.match(/<meta property="og:image" content="([^"]+)"/);
            if (ogImageMatch) {
              image = ogImageMatch[1];
              ogpSuccessCount++;
            }
          }
        } catch (error) {
          console.error(`âš ï¸  Failed to fetch OGP for ${item.url}:`, error);
        }

        // pubDate ã¾ãŸã¯ updated ã‚’ä½¿ç”¨
        const timestamp = item.pubDate ? new Date(item.pubDate) : new Date();

        results.push({
          sourceId: item.sourceId,
          sourceName: item.sourceName,
          title: item.title,
          url: item.url,
          timestamp,
          image,
          summary,
        });
      }

      console.log(`âœ… Step 2 complete: ${ogpSuccessCount}/${newItems.length} OGP images fetched`);
      return results;
    });

    // Step 3: LLMå‡¦ç† (ã‚«ãƒ†ã‚´ãƒª + ã‚µãƒãƒªãƒ¼ç”Ÿæˆ)
    const processedItems = await step.do("LLM processing for category and summary", async () => {
      console.log(`ğŸ¤– Step 3: Processing ${itemsWithOGP.length} items with LLM...`);
      // TODO: AI bindings ã‚’ä½¿ã£ã¦ã‚«ãƒ†ã‚´ãƒªã¨ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ
      // ç¾åœ¨ã¯ä»®å®Ÿè£…ã¨ã—ã¦ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
      const processed = itemsWithOGP.map((item) => ({
        ...item,
        category: "Infrastructure", // TODO: LLMã§åˆ¤å®š
        summary: item.summary.substring(0, 200), // TODO: LLMã§è¦ç´„
      }));
      console.log(`âœ… Step 3 complete: ${processed.length} items processed`);
      return processed;
    });

    // Step 4: D1ä¿å­˜
    await step.do("Save to D1 database", async () => {
      console.log(`ğŸ’¾ Step 4: Saving ${processedItems.length} items to database...`);
      for (const item of processedItems) {
        await db.insert(schema.radarItems).values({
          title: item.title,
          source: item.sourceId,
          sourceName: item.sourceName,
          category: item.category,
          summary: item.summary,
          image: item.image,
          url: item.url,
          timestamp: item.timestamp,
        });
      }

      console.log(`âœ… Step 4 complete: ${processedItems.length} items saved`);
      return { saved: processedItems.length };
    });

    return `Workflow completed: ${processedItems.length} items saved`;
  }
}
